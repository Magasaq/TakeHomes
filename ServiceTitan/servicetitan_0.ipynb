{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a19fb741",
   "metadata": {},
   "source": [
    "# Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "358ade5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pandas import json_normalize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "78f49db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vip = pd.read_csv(\"vip_customers.txt\", header=None)\n",
    "orders = pd.read_pickle(\"customer_orders.pkl\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768d361d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "fc6295e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import json_normalize\n",
    "\n",
    "class CustomerDataExtractor:\n",
    "    def __init__(self, orders, vip):\n",
    "        self.orders = orders\n",
    "        self.vip = vip\n",
    "        self.vip_set = set(vip[0].dropna().astype(int).unique())  # precompute for speed\n",
    "\n",
    "        # Define columns as class attributes for easy reuse\n",
    "        self.INT_COLUMNS = ['order_id', 'customer_id', 'product_id', 'item_quantity']\n",
    "        self.DATE_COLUMNS = ['registration_date', 'order_date']\n",
    "        self.STR_COLUMNS = ['customer_name', 'product_name', 'category']\n",
    "        self.ID_COLUMNS = ['customer_id', 'order_id', 'product_id']\n",
    "        # Category mapping dictionary\n",
    "        self.category_map = {\n",
    "            1: 'Electronics',\n",
    "            2: 'Apparel',\n",
    "            3: 'Books',\n",
    "            4: 'Home Goods'\n",
    "        }\n",
    "\n",
    "    def clean_quantity(self, series: pd.Series) -> pd.Series:\n",
    "        series_clean = series.astype(str).str.strip().str.upper()\n",
    "        series_clean = series_clean.replace('FREE', '0')\n",
    "        return pd.to_numeric(series_clean, errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "    def clean_order_id(self, series: pd.Series) -> pd.Series:\n",
    "        series_str = series.astype(str).replace(['None', 'nan', 'NaN'], pd.NA)\n",
    "        extracted = series_str.str.extract(r'(\\d+)')[0]\n",
    "        return extracted.astype('Int64')\n",
    "\n",
    "    def clean_unit_price(self, series: pd.Series) -> pd.Series:\n",
    "        invalid_vals = {'INVALID', 'invalid', 'N/A', 'NA', ''}\n",
    "        series_clean = series.astype(str).replace(invalid_vals, np.nan)\n",
    "        series_clean = series_clean.str.replace(r'[$,]', '', regex=True)\n",
    "        return pd.to_numeric(series_clean, errors='coerce')\n",
    "\n",
    "\n",
    "    def clean_data(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        # Clean order_id\n",
    "        df['order_id'] = self.clean_order_id(df['order_id'])\n",
    "\n",
    "        # Drop rows with missing critical IDs\n",
    "        df = df.dropna(subset=self.ID_COLUMNS).reset_index(drop=True)\n",
    "\n",
    "        # Clean unit_price\n",
    "        df['unit_price'] = self.clean_unit_price(df['unit_price'])\n",
    "\n",
    "        # Clean item_quantity\n",
    "        df['item_quantity'] = self.clean_quantity(df['item_quantity'])\n",
    "\n",
    "        # Convert ID columns to nullable int\n",
    "        df[self.ID_COLUMNS] = df[self.ID_COLUMNS].astype('Int64')\n",
    "\n",
    "        # Convert date columns to datetime with inference and error coercion\n",
    "        df[self.DATE_COLUMNS] = df[self.DATE_COLUMNS].apply(\n",
    "            lambda col: pd.to_datetime(col, errors='coerce', infer_datetime_format=True)\n",
    "        )\n",
    "\n",
    "        # Ensure string columns are of string dtype\n",
    "        df[self.STR_COLUMNS] = df[self.STR_COLUMNS].astype(str)\n",
    "        df['is_vip'] = [True if customer_id in self.vip_set else False for customer_id in df['customer_id']]\n",
    "\n",
    "        # Add is_vip column\n",
    "        #df['is_vip'] = df['customer_id'].apply(self.is_vip)\n",
    "\n",
    "        # Calculate total_item_price and total_order_value_percentage\n",
    "        df['total_item_price'] = df['unit_price'] * df['item_quantity']\n",
    "        order_totals = df.groupby('order_id')['total_item_price'].transform('sum')\n",
    "        df['total_order_value_percentage'] = df['total_item_price'] / order_totals\n",
    "\n",
    "        # Map categories and fill unmapped with 'Misc'\n",
    "        df['category'] = df['category'].map(self.category_map).fillna('Misc')\n",
    "\n",
    "        # Sort the dataframe\n",
    "        df.sort_values(by=['customer_id', 'order_id', 'product_id'], inplace=True)\n",
    "        return df\n",
    "\n",
    "    def extract(self) -> pd.DataFrame:\n",
    "        # Normalize orders and items JSON data\n",
    "        cleaned_data = [\n",
    "            {**customer, 'orders': customer.get('orders', [])}\n",
    "            for customer in self.orders\n",
    "        ]\n",
    "\n",
    "        for customer in cleaned_data:\n",
    "            customer['orders'] = [\n",
    "                {**order, 'items': order.get('items', [])}\n",
    "                for order in customer['orders']\n",
    "            ]\n",
    "\n",
    "        orders_df = json_normalize(\n",
    "            cleaned_data,\n",
    "            record_path='orders',\n",
    "            meta=['id', 'name', 'registration_date']\n",
    "        )\n",
    "\n",
    "        items_df = json_normalize(\n",
    "            cleaned_data,\n",
    "            record_path=['orders', 'items'],\n",
    "            meta=[['id'], ['orders', 'order_id']],\n",
    "            record_prefix='item_',\n",
    "            meta_prefix=''\n",
    "        )\n",
    "\n",
    "        # Rename columns for clarity and consistency\n",
    "        items_df.rename(columns={\n",
    "            'id': 'customer_id',\n",
    "            'orders.order_id': 'order_id',\n",
    "            'item_item_id': 'product_id',\n",
    "            'item_product_name': 'product_name',\n",
    "            'item_category': 'category',\n",
    "            'item_price': 'unit_price',\n",
    "            'item_quantity': 'item_quantity'\n",
    "        }, inplace=True)\n",
    "\n",
    "        orders_df.rename(columns={\n",
    "            'id': 'customer_id',\n",
    "            'name': 'customer_name'\n",
    "        }, inplace=True)\n",
    "\n",
    "        # Drop unneeded columns\n",
    "        orders_df.drop(columns=['items', 'shipping_address'], errors='ignore', inplace=True)\n",
    "        print(orders_df.columns)\n",
    "        print(items_df.columns)\n",
    "        \n",
    "        # Merge orders and items on customer_id and order_id\n",
    "        data = pd.merge(orders_df, items_df, on=['customer_id', 'order_id'], how='outer')\n",
    "\n",
    "        # Clean and finalize data\n",
    "        data = self.clean_data(data)\n",
    "\n",
    "        return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "ccb07cbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['order_id', 'order_date', 'order_total_value', 'customer_id',\n",
      "       'customer_name', 'registration_date'],\n",
      "      dtype='object')\n",
      "Index(['product_id', 'product_name', 'category', 'unit_price', 'item_quantity',\n",
      "       'customer_id', 'order_id'],\n",
      "      dtype='object')\n",
      "   order_id          order_date  order_total_value  customer_id customer_name  \\\n",
      "0         3 2023-09-06 00:42:50           0.000000            1    Customer 1   \n",
      "1         5 2024-08-28 19:37:56         -57.165786            2    Customer 2   \n",
      "2         5 2024-08-28 19:37:56         -57.165786            2    Customer 2   \n",
      "3         5 2024-08-28 19:37:56         -57.165786            2    Customer 2   \n",
      "4         5 2024-08-28 19:37:56         -57.165786            2    Customer 2   \n",
      "\n",
      "    registration_date  product_id        product_name category  unit_price  \\\n",
      "0 2022-12-31 04:19:19           1  Item 1 for Order 3     Misc      377.96   \n",
      "1 2022-05-27 00:23:28           1  Item 1 for Order 5     Misc      342.68   \n",
      "2 2022-05-27 00:23:28           2  Item 2 for Order 5     Misc      134.09   \n",
      "3 2022-05-27 00:23:28           3  Item 3 for Order 5     Misc      295.97   \n",
      "4 2022-05-27 00:23:28           4  Item 4 for Order 5     Misc      316.01   \n",
      "\n",
      "   item_quantity  is_vip  total_item_price  total_order_value_percentage  \n",
      "0              1    True            377.96                      1.000000  \n",
      "1              2   False            685.36                      0.305233  \n",
      "2              0   False              0.00                      0.000000  \n",
      "3              1   False            295.97                      0.131813  \n",
      "4              4   False           1264.04                      0.562954  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lx/8785bxd97hl0x_cz6tbcltlr0000gn/T/ipykernel_6632/748295712.py:59: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  lambda col: pd.to_datetime(col, errors='coerce', infer_datetime_format=True)\n",
      "/var/folders/lx/8785bxd97hl0x_cz6tbcltlr0000gn/T/ipykernel_6632/748295712.py:59: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  lambda col: pd.to_datetime(col, errors='coerce', infer_datetime_format=True)\n"
     ]
    }
   ],
   "source": [
    "extractor = CustomerDataExtractor(orders, vip)\n",
    "cleaned_df = extractor.extract()\n",
    "print(cleaned_df.head())\n",
    "\n",
    "# Export to CSV\n",
    "cleaned_df.to_csv('cleaned_customer_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7c9635",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tqopt-3K6yoEQd-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
